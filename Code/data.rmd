---
title: "Housing Data"
output: html_notebook
---

```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(reshape2)
library(lubridate)
```

```{r}
rates <- read.csv('mortgage_rate.csv', header=TRUE)

#convert DATE column to date format
rates$DATE <- as.Date(rates$DATE, format = "%m/%d/%y")

#add year and month columns to later merge with other data
rates$year <- year(rates$DATE)
rates$month <- month(rates$DATE, label=TRUE)

#keep only the first instance of rate data for each month
rates_1st <- aggregate(MORTGAGE30US ~ month + year, rates, FUN = function(x) x[1])

head(rates_1st)
```

```{r}
cpi <- read.csv('cpi.csv', header=TRUE)

#reshape monthly columns to one column
cpi_transform <- melt(cpi, id.vars = "Year", variable.name = "month", value.name = "cpi") %>% rename(year = Year)

head(cpi_transform)
```

```{r}
listings <- read.csv('active_listing.csv', header=TRUE)

#convert DATE column to date format
listings$observation_date <- as.Date(listings$observation_date, format = "%Y-%m-%d")

#add year and month columns to later merge with other data
listings$year <- year(listings$observation_date)
listings$month <- month(listings$observation_date, label=TRUE)

head(listings)
```

```{r}
value_index <- read.csv('zillow_home_value_index.csv', header=TRUE)
head(value_index)

#reshape date columns and convert to datetime format
price <- value_index %>%
  pivot_longer(cols = starts_with("X"),
               names_to = "date",
               values_to = "value") %>%
  mutate(date = gsub("X", "", date),
         date = as.Date(date, format = "%m.%d.%y")) %>%
  mutate(date = floor_date(date, unit = "month"))

#rename columns for merge with final dataset
price <- price %>% rename(ST = State, CTYNAME = RegionName, STATE = StateCodeFIPS, COUNTY = MunicipalCodeFIPS)

price
```

```{r}
pop_2010_2020 <- read.csv('population_2010_2020.csv', header=TRUE)
pop_2020_2022 <- read.csv('population_2020_2022.csv', header=TRUE)

#combine both datasets into one
pop_2010_2022 <- merge(pop_2010_2020, pop_2020_2022, by = c("STATE", "COUNTY", "STNAME", "CTYNAME"))
pop_10_22 <- pop_2010_2022[, c("STATE", "COUNTY", "STNAME", "CTYNAME", "POPESTIMATE2010", "POPESTIMATE2011", "POPESTIMATE2012", "POPESTIMATE2013", "POPESTIMATE2014", "POPESTIMATE2015", "POPESTIMATE2016", "POPESTIMATE2017", "POPESTIMATE2018", "POPESTIMATE2019", "POPESTIMATE2020.y", "POPESTIMATE2021", "POPESTIMATE2022")]

#filter by counties with a significant population (greater than 2,000,000)
sig_pop <- pop_10_22 %>% filter(COUNTY != 0, POPESTIMATE2022 > 2000000)
sig_pop
#reshape population dataset and convert column names to years
pop <- sig_pop %>%
  pivot_longer(cols = starts_with("POPESTIMATE"),
               names_to = "year",
               values_to = "pop") %>%
  mutate(year = gsub("POPESTIMATE", "", year)) %>%
  mutate(year = gsub(".y", "", year)) %>%
  mutate(year = as.numeric(year))

#top 16 counties with population data
pop

county_list <- sig_pop[order(sig_pop$STATE), 1:4]
row.names(county_list) <- NULL

#add record ID and reorder columns
county_list <- county_list %>%
  mutate(ID = row_number()) %>%
  select(ID, STATE, COUNTY, STNAME, CTYNAME)

#list of counties with >2,000,000 population
county_list
```

```{r}
#create months dataframe for merging
months_seq <- seq(from = as.Date("2010-01-01"), to = as.Date("2023-05-01"), by = "1 month")
years <- year(months_seq)
months <- month(months_seq, label=TRUE)

T1 <- data.frame(date = months_seq, year = years, month = months)

#merge mortgage rate data
T1_mortgage <- merge(T1, rates_1st, by = c("year", "month"), all.x=TRUE) %>% arrange(date)

#merge cpi data
T1_mortgage_cpi <- merge(T1_mortgage, cpi_transform, by = c("year", "month"), all.x=TRUE) %>% arrange(date)

#merge active listings data
T1_mortgage_cpi_listings <- merge(T1_mortgage_cpi, listings, by = c("year", "month"), all.x=TRUE) %>% arrange(date)

```

```{r}
#plot mortgage rates
plot(T1_mortgage$date, T1_mortgage$MORTGAGE30US, type="l", xlab="Date", ylab="Rate", main="mortgage_rate")
```

```{r}
#plot cpi
plot(T1_mortgage_cpi$date, T1_mortgage_cpi$cpi, type="l", xlab="Date", ylab="CPI", main="CPI")
```

```{r}
#plot active listings
plot(T1_mortgage_cpi_listings$date, T1_mortgage_cpi_listings$ACTLISCOUUS, type="l", xlab="Date", ylab="Active Listings", main="Active Listings")
```

## The 'final_sorted' data set has 80 NA's in the population field becuase of missing data for 2023 Jan - May.

```{r}
#combine mortgage rates, cpi, active listings and counties
combined_data <- merge(T1_mortgage_cpi_listings, county_list, by=NULL)
combined_data

#add population data
combined_data_pop <- merge(combined_data, pop, by = c("year", "STATE", "COUNTY", "STNAME", "CTYNAME"), all.x=TRUE)
combined_data_pop

#combine previous dataset with Zillow home values by county
final <- combined_data_pop %>%
  left_join(price, by = c("date", "CTYNAME", "STATE", "COUNTY"))

#select relevant fields
final <- final %>% select(ID, STATE, COUNTY, STNAME, CTYNAME, date, year, month, MORTGAGE30US, cpi, ACTLISCOUUS, pop, value)

#sort by date and filter only data points where active listings data exists (everything after June 2016)
final_sorted <- final %>%
  arrange(ID, date) %>%
  filter(date >= "2016-07-01")

removed_records <- final_sorted[!complete.cases(final_sorted), ]  
final_sorted <- final_sorted[complete.cases(final_sorted), ]

final_sorted
summary(final_sorted)
```

```{r}
# install DAAG package
library(DAAG)

# set seed
set.seed(42)

# split dataset into train, validate, test proportions
train_prop <- .6
validate_prop <- .2

# sample the data set
rand_indices <- sample(1:nrow(final_sorted))

# calculate how many records for each split
n_train <- round(train_prop * nrow(final_sorted))
n_validate <- round(validate_prop * nrow(final_sorted))
n_test <- nrow(final_sorted) - n_train - n_validate

# determine the subsets
train_set <- final_sorted[rand_indices[1:n_train], ]
validate_set <- final_sorted[rand_indices[(n_train + 1):(n_train + n_validate)], ]
test_set <- final_sorted[rand_indices[(n_train + n_validate + 1):nrow(final_sorted)], ]
```

```{r}
# build linear regession models
lm_rates <- lm(value ~ MORTGAGE30US + CTYNAME, data=train_set)
lm_cpi <- lm(value ~ cpi + CTYNAME, data=train_set)
lm_listings <- lm(value ~ ACTLISCOUUS + CTYNAME, data=train_set)
lm_pop <- lm(value ~ pop + CTYNAME, data=train_set)
lm_all <- lm(value ~ MORTGAGE30US + cpi + ACTLISCOUUS + pop + CTYNAME, data=train_set)

# review training summaries
summary(lm_rates)
summary(lm_cpi)
summary(lm_listings)
summary(lm_pop)
summary(lm_all)
```

```{r}
# for top 3 adjusted R-square, run validation sets and compare

# cpi val
lm_cpi_pred <- predict(lm_cpi, newdata = validate_set)
plot(validate_set$value, lm_cpi_pred, xlab='Actual', ylab='Pred', main='CPI, val set')

# listings val
lm_listings_pred <- predict(lm_listings, newdata = validate_set)
plot(validate_set$value, lm_listings_pred, xlab='Actual', ylab='Pred', main='Listings, val set')

# all val
lm_all_pred <- predict(lm_all, newdata = validate_set)
plot(validate_set$value, lm_all_pred, xlab='Actual', ylab='Pred', main='All, val set')
```

```{r}
# find the root mean square errors
lm_cpi_pred_rmse <- sqrt(mean((lm_cpi_pred - validate_set$value)^2, na.rm=TRUE))
lm_listings_pred_rmse <- sqrt(mean((lm_listings_pred - validate_set$value)^2, na.rm=TRUE))
lm_all_pred_rmse <- sqrt(mean((lm_all_pred - validate_set$value)^2, na.rm=TRUE))

sprintf('rmse of cpi validation set is %s', round(lm_cpi_pred_rmse, 2))
sprintf('rmse of listings validation set is %s', round(lm_listings_pred_rmse, 2))
sprintf('rmse of all validation set is %s', round(lm_all_pred_rmse, 2))
```

```{r}
# run final model with best fit using the test data
lm_all_test <- predict(lm_all, newdata = test_set)
plot(test_set$value, lm_all_test, xlab='Actual', ylab='Pred', main='All, test set')
lm_all_test_rmse <- sqrt(mean((lm_all_test - test_set$value)^2, na.rm=TRUE))
sprintf('rmse of all test set is %s', round(lm_all_test_rmse, 2))

```

## Plot of residuals vs predicted values shows heteroscedasticity.

## Relationship is non-linear -\> explore other models

```{r}
# Plot residuals vs predicted values

predicted_all <- lm_all$fitted.values
residuals <- lm_all$residuals
plot(predicted_all, residuals,
     main = "Res vs. Pred Values",
     xlab = "Predicted Values",
     ylab = "Residuals")
abline(h=0, lty=2)
```

## Transforming the dependent variable using 'log(value)' normalizes the residuals vs predicted values plot.

```{r}
# Test log-linear model
lm_log_all <- lm(log(value) ~ MORTGAGE30US + cpi + ACTLISCOUUS + pop + CTYNAME, data=train_set)
summary(lm_log_all)

predicted_log_all <- lm_log_all$fitted.values
residuals_log <- lm_log_all$residuals
plot(predicted_log_all, residuals_log,
     main = "Res vs. Pred Values",
     xlab = "Predicted Values",
     ylab = "Residuals")
abline(h=0, lty=2)
```

## Looking at the correlation matrix mortgage rate and cpi are highly correlated while active listings and cpi are negatively correlated.

```{r}
# plot correlation matrix

library(corrplot)
cor_matrix <- cor(train_set[, c("MORTGAGE30US", "cpi", "ACTLISCOUUS", "pop")])
corrplot(cor_matrix, method = "color")
```

```{r}

# load packages
library(randomForest)
library(scales)

# build using R package randomForest; set mtry
rf_all <- randomForest(value ~ MORTGAGE30US + cpi + ACTLISCOUUS + pop + CTYNAME, data=train_set, importance=TRUE, mtry=5)

# review rf model
rf_all
summary(rf_all)
round(importance(rf_all), 2)
varImpPlot(rf_all)

# predict against validation set
rf_all_pred <- predict(rf_all, newdata = test_set)
rf_all_pred_df <- data.frame(state = test_set$STNAME, date = test_set$date, county = test_set$CTYNAME, actual = test_set$value, predicted = rf_all_pred)

# get rmse
rf_rmse <- sqrt(mean((rf_all_pred - test_set$value)^2))

# calculate difference between predict and actuals
rf_all_pred_df$diff <- rf_all_pred_df$predicted - rf_all_pred_df$actual
rf_all_pred_df$diff_is_pos <- if_else(rf_all_pred_df$diff >= 0, TRUE, FALSE)

# plot actual vs predicted over time
ggplot(rf_all_pred_df, aes(x = date)) +
  geom_line(aes(y = actual, color = "Actual")) +
  geom_line(aes(y = predicted, color = "Predicted", linetype = "Predicted"), linetype = "dashed") +
  labs(x = "Date", y = "Value", title = "Predicted vs Actual") +
  scale_y_continuous(labels = scales::comma) +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"), labels = c("Actual", "Predicted")) +
  scale_linetype_manual(values = c("Predicted" = "dashed"), labels = "Predicted") +
  theme_bw() +
  facet_wrap(~ county, ncol = 4) +
  theme(legend.position = "right")

# group by county
rf_all_pred_group <- rf_all_pred_df %>%
  group_by(rf_all_pred_df$county) %>%
  summarize(
    count = n(),
    mean_value = mean(diff),
    median_value = median(diff),
    min_value = min(diff),
    max_value = max(diff),
    pred_over = sum(diff_is_pos),
    pred_under = count - sum(diff_is_pos)
    )

# sort groups by median values
rf_all_pred_group_sort <- arrange(rf_all_pred_group, desc(median_value))

# review data
rf_all_pred_df_summary <- summary(rf_all_pred_df)
rf_all_pred_df_summary
rf_all_pred_group_sort

# plot predictions
ggplot(rf_all_pred_df, aes(x = actual, y = predicted, color = as.logical(diff_is_pos))) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") + 
  scale_y_continuous(labels = scales::comma) +
  scale_x_continuous(labels = scales::comma) +
  labs(x = "Actual", y = "Predicted", title = "Predicted vs Actual", color = "Prediction over/under") +
  theme_bw()

# plot predictions by county
ggplot(rf_all_pred_df, aes(x = actual, y = predicted, color = as.logical(diff_is_pos))) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") + 
  scale_y_continuous(labels = scales::comma) +
  scale_x_continuous(labels = scales::comma) +
  labs(x = "Actual", y = "Predicted", title = "Predicted vs Actual", color = "Prediction over/under") +
  theme_bw() + 
  facet_wrap(~ county, ncol = 4) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```
