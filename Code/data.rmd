---
title: "Housing Data"
output: html_notebook
---

# Load required libraries

```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(reshape2)
library(lubridate)
library(DAAG)
library(corrplot)
library(ggplot2)
library(randomForest)
library(scales)
library(forecast)

```

# Prepare the data

## Ingest, cleanse, and merge data sets

```{r}
rates <- read.csv('mortgage_rate.csv', header=TRUE)

#convert DATE column to date format
rates$DATE <- as.Date(rates$DATE, format = "%m/%d/%y")

#add year and month columns to later merge with other data
rates$year <- year(rates$DATE)
rates$month <- month(rates$DATE, label=TRUE)

#keep only the first instance of rate data for each month
rates_1st <- aggregate(MORTGAGE30US ~ month + year, rates, FUN = function(x) x[1])

head(rates_1st)
```

```{r}
cpi <- read.csv('cpi.csv', header=TRUE)

#reshape monthly columns to one column
cpi_transform <- melt(cpi, id.vars = "Year", variable.name = "month", value.name = "cpi") %>% rename(year = Year)

head(cpi_transform)
```

```{r}
listings <- read.csv('active_listing.csv', header=TRUE)

#convert DATE column to date format
listings$observation_date <- as.Date(listings$observation_date, format = "%Y-%m-%d")

#add year and month columns to later merge with other data
listings$year <- year(listings$observation_date)
listings$month <- month(listings$observation_date, label=TRUE)

head(listings)
```

```{r}
value_index <- read.csv('zillow_home_value_index.csv', header=TRUE)
head(value_index)

#reshape date columns and convert to datetime format
price <- value_index %>%
  pivot_longer(cols = starts_with("X"),
               names_to = "date",
               values_to = "value") %>%
  mutate(date = gsub("X", "", date),
         date = as.Date(date, format = "%m.%d.%y")) %>%
  mutate(date = floor_date(date, unit = "month"))

#rename columns for merge with final dataset
price <- price %>% rename(ST = State, CTYNAME = RegionName, STATE = StateCodeFIPS, COUNTY = MunicipalCodeFIPS)

price
```

```{r}
pop_2010_2020 <- read.csv('population_2010_2020.csv', header=TRUE)
pop_2020_2022 <- read.csv('population_2020_2022.csv', header=TRUE)

#combine both datasets into one
pop_2010_2022 <- merge(pop_2010_2020, pop_2020_2022, by = c("STATE", "COUNTY", "STNAME", "CTYNAME"))
pop_10_22 <- pop_2010_2022[, c("STATE", "COUNTY", "STNAME", "CTYNAME", "POPESTIMATE2010", "POPESTIMATE2011", "POPESTIMATE2012", "POPESTIMATE2013", "POPESTIMATE2014", "POPESTIMATE2015", "POPESTIMATE2016", "POPESTIMATE2017", "POPESTIMATE2018", "POPESTIMATE2019", "POPESTIMATE2020.y", "POPESTIMATE2021", "POPESTIMATE2022")]

#filter by counties with a significant population (greater than 2,000,000)
sig_pop <- pop_10_22 %>% filter(COUNTY != 0, POPESTIMATE2022 > 2000000)
sig_pop
#reshape population dataset and convert column names to years
pop <- sig_pop %>%
  pivot_longer(cols = starts_with("POPESTIMATE"),
               names_to = "year",
               values_to = "pop") %>%
  mutate(year = gsub("POPESTIMATE", "", year)) %>%
  mutate(year = gsub(".y", "", year)) %>%
  mutate(year = as.numeric(year))

#top 16 counties with population data
pop

county_list <- sig_pop[order(sig_pop$STATE), 1:4]
row.names(county_list) <- NULL

#add record ID and reorder columns
county_list <- county_list %>%
  mutate(ID = row_number()) %>%
  select(ID, STATE, COUNTY, STNAME, CTYNAME)

#list of counties with >2,000,000 population
county_list
```

```{r}
#create months dataframe for merging
months_seq <- seq(from = as.Date("2010-01-01"), to = as.Date("2023-05-01"), by = "1 month")
years <- year(months_seq)
months <- month(months_seq, label=TRUE)

T1 <- data.frame(date = months_seq, year = years, month = months)

#merge mortgage rate data
T1_mortgage <- merge(T1, rates_1st, by = c("year", "month"), all.x=TRUE) %>% arrange(date)

#merge cpi data
T1_mortgage_cpi <- merge(T1_mortgage, cpi_transform, by = c("year", "month"), all.x=TRUE) %>% arrange(date)

#merge active listings data
T1_mortgage_cpi_listings <- merge(T1_mortgage_cpi, listings, by = c("year", "month"), all.x=TRUE) %>% arrange(date)

```

```{r}
#plot mortgage rates
plot(T1_mortgage$date, T1_mortgage$MORTGAGE30US, type="l", xlab="Date", ylab="Rate", main="mortgage_rate")
```

```{r}
#plot cpi
plot(T1_mortgage_cpi$date, T1_mortgage_cpi$cpi, type="l", xlab="Date", ylab="CPI", main="CPI")
```

```{r}
#plot active listings
plot(T1_mortgage_cpi_listings$date, T1_mortgage_cpi_listings$ACTLISCOUUS, type="l", xlab="Date", ylab="Active Listings", main="Active Listings")
```

## The 'final_sorted' data set has 80 NA's in the population field becuase of missing data for 2023 Jan - May.

```{r}
#combine mortgage rates, cpi, active listings and counties
combined_data <- merge(T1_mortgage_cpi_listings, county_list, by=NULL)
combined_data

#add population data
combined_data_pop <- merge(combined_data, pop, by = c("year", "STATE", "COUNTY", "STNAME", "CTYNAME"), all.x=TRUE)
combined_data_pop

#combine previous dataset with Zillow home values by county
final <- combined_data_pop %>%
  left_join(price, by = c("date", "CTYNAME", "STATE", "COUNTY"))

#select relevant fields
final <- final %>% select(ID, STATE, COUNTY, STNAME, CTYNAME, date, year, month, MORTGAGE30US, cpi, ACTLISCOUUS, pop, value)

#sort by date and filter only data points where active listings data exists (everything after June 2016)
final_sorted <- final %>%
  arrange(ID, date) %>%
  filter(date >= "2016-07-01")

removed_records <- final_sorted[!complete.cases(final_sorted), ]  
final_sorted <- final_sorted[complete.cases(final_sorted), ]

final_sorted
summary(final_sorted)
```

# Split data into train, validation, test sets.

```{r}

# set seed
set.seed(42)

# split dataset into train, validate, test proportions
train_prop <- .6
validate_prop <- .2

# sample the data set
rand_indices <- sample(1:nrow(final_sorted))

# calculate how many records for each split
n_train <- round(train_prop * nrow(final_sorted))
n_validate <- round(validate_prop * nrow(final_sorted))
n_test <- nrow(final_sorted) - n_train - n_validate

# determine the subsets
train_set <- final_sorted[rand_indices[1:n_train], ]
validate_set <- final_sorted[rand_indices[(n_train + 1):(n_train + n_validate)], ]
test_set <- final_sorted[rand_indices[(n_train + n_validate + 1):nrow(final_sorted)], ]
```

```{r}
# build linear regession models
lm_rates <- lm(value ~ MORTGAGE30US + CTYNAME, data=train_set)
lm_cpi <- lm(value ~ cpi + CTYNAME, data=train_set)
lm_listings <- lm(value ~ ACTLISCOUUS + CTYNAME, data=train_set)
lm_pop <- lm(value ~ pop + CTYNAME, data=train_set)
lm_all <- lm(value ~ MORTGAGE30US + cpi + ACTLISCOUUS + pop + CTYNAME, data=train_set)

# review training summaries
summary(lm_rates)
summary(lm_cpi)
summary(lm_listings)
summary(lm_pop)
summary(lm_all)
```

```{r}
# for top 3 adjusted R-square, run validation sets and compare

# cpi val
lm_cpi_pred <- predict(lm_cpi, newdata = validate_set)
plot(validate_set$value, lm_cpi_pred, xlab='Actual', ylab='Pred', main='CPI, val set')

# listings val
lm_listings_pred <- predict(lm_listings, newdata = validate_set)
plot(validate_set$value, lm_listings_pred, xlab='Actual', ylab='Pred', main='Listings, val set')

# all val
lm_all_pred <- predict(lm_all, newdata = validate_set)
plot(validate_set$value, lm_all_pred, xlab='Actual', ylab='Pred', main='All, val set')
```

```{r}
# find the root mean square errors
lm_cpi_pred_rmse <- sqrt(mean((lm_cpi_pred - validate_set$value)^2, na.rm=TRUE))
lm_listings_pred_rmse <- sqrt(mean((lm_listings_pred - validate_set$value)^2, na.rm=TRUE))
lm_all_pred_rmse <- sqrt(mean((lm_all_pred - validate_set$value)^2, na.rm=TRUE))

sprintf('rmse of cpi validation set is %s', round(lm_cpi_pred_rmse, 2))
sprintf('rmse of listings validation set is %s', round(lm_listings_pred_rmse, 2))
sprintf('rmse of all validation set is %s', round(lm_all_pred_rmse, 2))
```

```{r}
# run final model with best fit using the test data
lm_all_test <- predict(lm_all, newdata = test_set)
plot(test_set$value, lm_all_test, xlab='Actual', ylab='Pred', main='All, test set')
lm_all_test_rmse <- sqrt(mean((lm_all_test - test_set$value)^2, na.rm=TRUE))
sprintf('rmse of all test set is %s', round(lm_all_test_rmse, 2))

```

## Plot of residuals vs predicted values shows heteroscedasticity.

## Relationship is non-linear -\> explore other models

```{r}
# Plot residuals vs predicted values

predicted_all <- lm_all$fitted.values
residuals <- lm_all$residuals
plot(predicted_all, residuals,
     main = "Res vs. Pred Values",
     xlab = "Predicted Values",
     ylab = "Residuals")
abline(h=0, lty=2)
```

## Transforming the dependent variable using 'log(value)' normalizes the residuals vs predicted values plot.

```{r}
# Test log-linear model
lm_log_all <- lm(log(value) ~ MORTGAGE30US + cpi + ACTLISCOUUS + pop + CTYNAME, data=train_set)
summary(lm_log_all)

predicted_log_all <- lm_log_all$fitted.values
residuals_log <- lm_log_all$residuals
plot(predicted_log_all, residuals_log,
     main = "Res vs. Pred Values",
     xlab = "Predicted Values",
     ylab = "Residuals")
abline(h=0, lty=2)
```

## Looking at the correlation matrix mortgage rate and cpi are highly correlated while active listings and cpi are negatively correlated.

```{r}
# plot correlation matrix

cor_matrix <- cor(train_set[, c("MORTGAGE30US", "cpi", "ACTLISCOUUS", "pop")])
corrplot(cor_matrix, method = "color")
```

# Linear Regression Model

```{r}

lm_pred <- predict(lm_log_all,newdata = test_set)
lm_pred_df <- data.frame(state = test_set$STNAME, date = test_set$date, county = test_set$CTYNAME, actual = log(test_set$value), predicted = lm_pred)
head(lm_pred_df)

# plot predicted value and actual value
ggplot(lm_pred_df, aes(x = date)) +
  geom_line(aes(y = actual, color = "Actual"),linetype = "solid", size = 0.5) +
  geom_line(aes(y = predicted, color = "Predicted", linetype = "Predicted"), linetype = "dashed", size = 0.5) +
  labs(x = "Date", y = "Value (Log)", title = "Linear Regression - Predicted vs Actual") +
  scale_y_continuous(labels = scales::comma) +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"), labels = c("Actual", "Predicted")) +
  scale_linetype_manual(values = c("Predicted" = "dashed"), labels = "Predicted") +
  theme_bw() +
  facet_wrap(~ county, ncol = 4) +
  theme(legend.position = "right")
```

```{r}
# Create variance column of predicted and actual
lm_pred_df$diff <- lm_pred_df$predicted - lm_pred_df$actual
lm_pred_df$diff_is_pos <- if_else(lm_pred_df$diff >= 0, TRUE, FALSE)
head(lm_pred_df)

## Filter results to 2021 onwards to get latest 
lm_pred_df_filtered <- lm_pred_df %>%
  filter(date >= as.Date("2021-01-01"))

# Plot County diff
ggplot(lm_pred_df_filtered, aes(x = actual, y = predicted, color = as.logical(diff_is_pos))) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") + 
  scale_y_continuous(labels = scales::comma) +
  scale_x_continuous(labels = scales::comma) +
  labs(x = "Actual", y = "Predicted", title = "Linear Regression - Predicted vs Actual (2021 Onwards)", color = "Prediction over/under") +
  theme_bw() + 
  facet_wrap(~ county, ncol = 4) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
# Create county summary table
lm_pred_group <- lm_pred_df_filtered %>%
  group_by(lm_pred_df_filtered$county) %>%
  summarize(
    count = n(),
    mean_value = mean(diff),
    median_value = median(diff),
    min_value = min(diff),
    max_value = max(diff),
    pred_over = sum(diff_is_pos),
    pred_under = count - sum(diff_is_pos)
  )
lm_pred_group
```

# Random Forest Model

# use built-in Random Forest function in R. Segment into counties and measure RMSE for model comparison.

```{r}

# build using R package randomForest; set mtry
rf_all <- randomForest(value ~ MORTGAGE30US + cpi + ACTLISCOUUS + pop + CTYNAME, data=train_set, importance=TRUE, mtry=5)

# review rf model
rf_all
summary(rf_all)
round(importance(rf_all), 2)
varImpPlot(rf_all)

# predict against validation set
rf_all_pred <- predict(rf_all, newdata = test_set)
rf_all_pred_df <- data.frame(state = test_set$STNAME, date = test_set$date, county = test_set$CTYNAME, actual = test_set$value, predicted = rf_all_pred)

# get rmse
rf_rmse <- sqrt(mean((rf_all_pred - test_set$value)^2))

# calculate difference between predict and actuals
rf_all_pred_df$diff <- rf_all_pred_df$predicted - rf_all_pred_df$actual
rf_all_pred_df$diff_is_pos <- if_else(rf_all_pred_df$diff >= 0, TRUE, FALSE)

# plot actual vs predicted over time
ggplot(rf_all_pred_df, aes(x = date)) +
  geom_line(aes(y = actual, color = "Actual")) +
  geom_line(aes(y = predicted, color = "Predicted", linetype = "Predicted"), linetype = "dashed") +
  labs(x = "Date", y = "Value", title = "Predicted vs Actual") +
  scale_y_continuous(labels = scales::comma) +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"), labels = c("Actual", "Predicted")) +
  scale_linetype_manual(values = c("Predicted" = "dashed"), labels = "Predicted") +
  theme_bw() +
  facet_wrap(~ county, ncol = 4) +
  theme(legend.position = "right")

# group by county
rf_all_pred_group <- rf_all_pred_df %>%
  group_by(rf_all_pred_df$county) %>%
  summarize(
    count = n(),
    mean_value = mean(diff),
    median_value = median(diff),
    min_value = min(diff),
    max_value = max(diff),
    pred_over = sum(diff_is_pos),
    pred_under = count - sum(diff_is_pos)
    )

# sort groups by median values
rf_all_pred_group_sort <- arrange(rf_all_pred_group, desc(median_value))

# review data
rf_all_pred_df_summary <- summary(rf_all_pred_df)
rf_all_pred_df_summary
rf_all_pred_group_sort

# plot predictions
ggplot(rf_all_pred_df, aes(x = actual, y = predicted, color = as.logical(diff_is_pos))) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") + 
  scale_y_continuous(labels = scales::comma) +
  scale_x_continuous(labels = scales::comma) +
  labs(x = "Actual", y = "Predicted", title = "Predicted vs Actual", color = "Prediction over/under") +
  theme_bw()

# plot predictions by county
ggplot(rf_all_pred_df, aes(x = actual, y = predicted, color = as.logical(diff_is_pos))) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") + 
  scale_y_continuous(labels = scales::comma) +
  scale_x_continuous(labels = scales::comma) +
  labs(x = "Actual", y = "Predicted", title = "Predicted vs Actual", color = "Prediction over/under") +
  theme_bw() + 
  facet_wrap(~ county, ncol = 4) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

```{r}
# create random forest models for each county to compare RMSE with ARIMA models
rf_list <- split(train_set, train_set$CTYNAME)

rf_models <- lapply(rf_list, function(x) {
  rf_model <- randomForest(value ~ MORTGAGE30US + cpi + ACTLISCOUUS + pop, data=x)
    return(rf_model)
  })

# RMSE of random forest models for each county

rf_rmse_df <- data.frame()

for(i in seq_along(rf_models)) {
  model <- rf_models[[i]]
  
  data <- rf_list[[i]]
  
  predictions <- predict(model, newdata = data)
  
  residuals <- predictions - data$value
  
  rf_rmse <- sqrt(mean(residuals^2))
  
  county_rmse <- data.frame(
    county = names(rf_models)[i],
    rmse = rf_rmse
  )
  
  rf_rmse_df <- rbind(rf_rmse_df, county_rmse)
}

print(rf_rmse_df)
```

# ARIMA Model

## First we will have to forecast the population data for the first 5 months of 2023. Once the forecasted population data is appended to the original data, we can create ARIMA models with exogenous variables for each of the 16 counties. The forecasted results will then be compared with the Random Forest model using RMSE.

```{r}

# forecast population data for 2023

counties <- unique(final$CTYNAME)

pop_models <- list()

for (county in counties) {
  df_county <- subset(final, CTYNAME == county)
  
  pop_ts <- ts(df_county$pop, start = c(2009, 8), frequency = 12)
  
  pop_models[[county]] <- auto.arima(pop_ts)
}

pop_forecasts <- list()
pop_forecasts_df <- data.frame()

for (county in names(pop_models)) {
  model <- pop_models[[county]]
  
  forecast <- forecast(model, h = 5)
  
  pop_forecasts[[county]] <- forecast
  
  forecast_df <- data.frame(
    date = seq(as.Date("2023-01-01"), by = "month", length.out =5),
    CTYNAME = county,
    pop = forecast
  )
  
  pop_forecasts_df <- rbind(pop_forecasts_df, forecast_df)
}

# rename population forecast to "pop"
colnames(pop_forecasts_df)[3] = "pop"

# format "pop" as integer
pop_forecasts_df$pop <- as.integer(pop_forecasts_df$pop)

# remove extraneous columns
pop_forecasts_df <- select(pop_forecasts_df, -c(pop.Lo.80,pop.Hi.80,pop.Lo.95,pop.Hi.95
))
```

```{r}
# combine forecasted population data with original data set

final_sorted_2023 <- final %>%
  arrange(ID, date) %>%
  filter(date >= "2016-07-01")

final_2023 <- merge(final_sorted_2023, pop_forecasts_df, by=c("date", "CTYNAME"), all=TRUE)

# filter by 2023 dates for forecasting
final_2023 <- final_2023 %>%
  mutate(pop = coalesce(pop.x, pop.y)) %>%
  select(-pop.x, -pop.y) %>%
  filter(date >= "2023-01-01")
```

```{r}
# fit ARIMA model for each county

counties <- unique(final_sorted$CTYNAME)

models <- list()

for (county in counties) {
  df_county <- subset(final_sorted, CTYNAME == county)
  
  price_ts <- ts(df_county$value, frequency = 12, start = c(2016, 7))
  
  xreg <- cbind(df_county$MORTGAGE30US, df_county$cpi, df_county$pop, df_county$ACTLISCOUUS)

  models[[county]] <- auto.arima(price_ts, xreg = xreg)
}

#models

# forecast ARIMA models

forecasts_arima <- list()

df_rmse <- data.frame()

for (county in names(models)) {
  model <- models[[county]]
  
  df_future_county <- subset(final_2023, CTYNAME == county)
  
  xreg_future <- cbind(df_future_county$MORTGAGE30US, df_future_county$cpi, df_future_county$pop, df_future_county$ACTLISCOUUS)
  
  forecast <- forecast(model, h = 5, xreg = xreg_future)
  
  forecasts_arima[[county]] <- forecast
  
  # calculate rmse for each county
  
  rmse = sqrt(mean((df_future_county$value - forecast$mean)^2))
  
  df_rmse <- rbind(df_rmse, data.frame(County = county, RMSE = rmse))
}

df_rmse
```

```{r}
# plot arima models

for (county in names(forecasts_arima)) {
  plot(forecasts_arima[[county]])
  }
```
